# Diabetes Prediction using K-Nearest Neighbors (KNN)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score
)
import seaborn as sns
import matplotlib.pyplot as plt


# Step 1: Load Dataset

data = pd.read_csv("diabetes.csv")
print(" First 5 rows of data:")
print(data.head())


# Step 2: Check for Null Values

print("\n Missing Values per Column:")
print(data.isnull().sum())


# Step 3: Replace Zeros with Mean

cols_to_replace = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

for column in cols_to_replace:
    data[column] = data[column].replace(0, np.nan)
    data[column] = data[column].fillna(round(data[column].mean(skipna=True)))


# Step 4: Feature & Target Selection
# ===============================
X = data.iloc[:, :8]   # First 8 columns as features
Y = data['Outcome']    # Target column


# Step 5: Split Dataset into Train & Test

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)


# Step 6: Outlier Detection using Boxplots

plt.figure(figsize=(12, 6))
sns.boxplot(data=data)
plt.title("Outlier Detection using Boxplots")
plt.show()

# Identify outliers using IQR
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).sum()

print("\nðŸ”¹ Number of Outliers per Feature:\n", outliers)


# Step 7: Initialize and Train KNN Model

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, Y_train)


# Step 8: Make Predictions

knn_pred = knn.predict(X_test)

# Step 9: Evaluate Model Performance

cm = confusion_matrix(Y_test, knn_pred)
accuracy = accuracy_score(Y_test, knn_pred)
error_rate = 1 - accuracy
precision = precision_score(Y_test, knn_pred)
recall = recall_score(Y_test, knn_pred)
f1 = f1_score(Y_test, knn_pred)

print("\nðŸ”¹ Model Evaluation Metrics:")
print("Confusion Matrix:\n", cm)
print("Accuracy Score:", accuracy)
print("Error Rate:", error_rate)
print("Precision Score:", precision)
print("Recall Score:", recall)
print("F1 Score:", f1)


# Step 10: Accuracy Comparison for Different K Values

accuracy_scores = []

for k in [3, 5, 7]:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, Y_train)
    knn_pred = knn.predict(X_test)
    acc = accuracy_score(Y_test, knn_pred)
    accuracy_scores.append(acc)
    print(f"K = {k} â†’ Accuracy = {acc * 100:.2f}%")

plt.plot([3, 5, 7], accuracy_scores, marker='o', color='blue')
plt.title("KNN Accuracy vs K Value")
plt.xlabel("K Value")
plt.ylabel("Accuracy")
plt.grid(True)
plt.show()
